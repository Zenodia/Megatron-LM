{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading gpt2 tokenizer\n",
      "[230, 298, 307, 228, 187, 172, 228, 185, 176, 228, 186, 296]\n"
     ]
    }
   ],
   "source": [
    "from megatron.tokenizer.tokenizer import build_debug\n",
    "#sample_doc='邻近皇宫萨纳雷斯河，穆斯林称为（阿拉伯语:المجريط，「水的来源」）。'\n",
    "raw_text='我们买了'\n",
    "vocab_f='/workspace/gpt_ckpt/vocab.json'\n",
    "merge_f='/workspace/gpt_ckpt/merges.txt'\n",
    "tokenizer=build_debug(vocab_f,merge_f, 'gpt')\n",
    "token_ids=tokenizer.tokenize(raw_text)\n",
    "print(token_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in gpt2tokenizer decode function  æĪĳä»¬ä¹°äºĨ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我们买了'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.detokenize(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "我们买了stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果 34988\n",
      "变动 38916\n",
      "较大 36463\n",
      "， 32471\n",
      "随时 36903\n",
      "关注 35192\n",
      "最新 35754\n",
      "思路 37054\n",
      "。 5163\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /workspace/cn/bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from megatron.tokenizer.tokenizer import build_debug\n",
    "#sample_doc='邻近皇宫是曼萨纳雷斯河，穆斯林称为（阿拉伯语:المجريط，「水的来源」）。'\n",
    "vocab_f='/workspace/cn/bpe/nHash/64k//vocab.json'\n",
    "merge_f='/workspace/cn/bpe/nHash/64k/merges.txt'\n",
    "tokenizer3=build_debug(vocab_f,merge_f, 'bpe')\n",
    "token_ids3=tokenizer.tokenize(sample_doc)\n",
    "tokens3=tokenizer3.decode_token_ids(token_ids3)    \n",
    "for tok3, tok_id3 in zip(tokens3,token_ids3):\n",
    "    print(tok3, tok_id3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "vocab_id_list=[v for (k,v) in tokenizer.vocab.items()] \n",
    "vocab_id_to_token_dict=tokenizer.inv_vocab\n",
    "masked_lm_prob=0.15\n",
    "cls_id=tokenizer.vocab['[CLS]']\n",
    "sep_id=tokenizer.vocab['[SEP]']\n",
    "mask_id=tokenizer.vocab['[MASK]']\n",
    "max_predictions_per_seq=512\n",
    "np_rng=np.random.default_rng(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "vocab_id_list2=[v for (k,v) in tokenizer2.vocab.items()] \n",
    "vocab_id_to_token_dict2=tokenizer.inv_vocab\n",
    "masked_lm_pro2b=0.15\n",
    "cls_id2=tokenizer2.vocab['[CLS]']\n",
    "sep_id2=tokenizer2.vocab['[SEP]']\n",
    "mask_id2=tokenizer2.vocab['[MASK]']\n",
    "max_predictions_per_seq2=512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "vocab_id_list3=[v for (k,v) in tokenizer3.vocab.items()] \n",
    "vocab_id_to_token_dict3=tokenizer3.inv_vocab\n",
    "masked_lm_pro2b=0.15\n",
    "cls_id2=tokenizer3.vocab['[CLS]']\n",
    "sep_id2=tokenizer3.vocab['[SEP]']\n",
    "mask_id2=tokenizer3.vocab['[MASK]']\n",
    "max_predictions_per_seq3=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random as np_rng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from megatron.data.dataset_utils import create_masked_lm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens, masked_lm_positions, masked_lm_labels, token_boundary= create_masked_lm_predictions(token_ids,\n",
    "                                 vocab_id_list, vocab_id_to_token_dict,\n",
    "                                 masked_lm_prob,\n",
    "                                 cls_id, sep_id, mask_id,\n",
    "                                 max_predictions_per_seq,\n",
    "                                 np_rng,\n",
    "                                 3,\n",
    "                                 True,\n",
    "                                 False,\n",
    "                                 False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([34988, 38916, 36463, 5, 36903, 35192, 35754, 37054, 5163],\n",
       " [3],\n",
       " [32471],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens, masked_lm_positions, masked_lm_labels, token_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens2, masked_lm_positions2,masked_lm_labels2, token_boundary2= create_masked_lm_predictions(token_ids2,\n",
    "                                 vocab_id_list2, vocab_id_to_token_dict2,\n",
    "                                 masked_lm_prob,\n",
    "                                 cls_id2, sep_id2, mask_id2,\n",
    "                                 max_predictions_per_seq2,\n",
    "                                 np_rng,\n",
    "                                 3,\n",
    "                                 True,\n",
    "                                 False,\n",
    "                                 False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens2, masked_lm_positions2,masked_lm_labels2, token_boundary2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
